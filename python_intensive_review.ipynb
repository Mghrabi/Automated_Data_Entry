{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Python Intensive Review for Interview Preparation\n",
        "\n",
        "This notebook covers comprehensive Python concepts for automation, APIs, desktop applications, and advanced programming patterns.\n",
        "\n",
        "## Table of Contents\n",
        "1. **Basic Python Fundamentals**\n",
        "2. **Data Structures & Algorithms**\n",
        "3. **Object-Oriented Programming**\n",
        "4. **Error Handling & Exceptions**\n",
        "5. **File I/O & Path Management**\n",
        "6. **APIs & HTTP Requests**\n",
        "7. **Desktop Automation (PyAutoGUI)**\n",
        "8. **Concurrency & Threading**\n",
        "9. **Testing & Debugging**\n",
        "10. **Advanced Python Features**\n",
        "11. **Performance Optimization**\n",
        "12. **Real-world Automation Patterns**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Basic Python Fundamentals\n",
        "\n",
        "### Variables, Data Types, and Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Blog Post Title\n",
            "Formatted: Blog Post Title\n",
            "Safe filename: blog_post_title\n",
            "BLOG POST #1\n",
            "\n",
            "TITLE: Blog Post Title\n",
            "\n",
            "Content goes here...\n",
            "\n",
            "---\n",
            "Post ID: 1\n",
            "User ID: 10\n",
            "Generated: 2025-07-20 20:57:59\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Basic data types and operations\n",
        "import time\n",
        "import platform\n",
        "from typing import List, Dict, Optional, Union, Tuple\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "# Variables and basic types\n",
        "name: str = \"Desktop Bot\"\n",
        "version: float = 1.0\n",
        "is_active: bool =  True \n",
        "\n",
        "data: Optional[Dict] = None\n",
        "\n",
        "# String operations (crucial for automation)\n",
        "text = \"Blog Post Title\"\n",
        "formatted_text = text.title()  # Capitalize each word\n",
        "safe_filename = text.replace(\" \", \"_\").lower()  # Create safe filename\n",
        "print(f\"Original: {text}\")\n",
        "print(f\"Formatted: {formatted_text}\")\n",
        "print(f\"Safe filename: {safe_filename}\")\n",
        "\n",
        "# F-strings and formatting (essential for dynamic content)\n",
        "post_id = 1\n",
        "user_id = 10\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "blog_content = f\"\"\"BLOG POST #{post_id}\n",
        "\n",
        "TITLE: {formatted_text}\n",
        "\n",
        "Content goes here...\n",
        "\n",
        "---\n",
        "Post ID: {post_id}\n",
        "User ID: {user_id}\n",
        "Generated: {timestamp}\n",
        "\"\"\"\n",
        "\n",
        "print(blog_content)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Data Structures & Algorithms\n",
        "\n",
        "### Lists, Dictionaries, Sets, and Comprehensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Post titles: ['First Post', 'Second Post', 'Third Post']\n",
            "User 1 posts: [{'id': 1, 'title': 'First Post', 'userId': 1}, {'id': 2, 'title': 'Second Post', 'userId': 1}]\n",
            "Formatted titles: ['FIRST POST', 'SECOND POST', 'THIRD POST']\n",
            "Post lookup: {1: 'First Post', 2: 'Second Post', 3: 'Third Post'}\n",
            "Title lengths: {'First Post': 10, 'Second Post': 11, 'Third Post': 10}\n",
            "Unique user IDs: {1, 2}\n",
            "Unique words: {'first', 'third', 'post', 'second'}\n",
            "First: First Post, Last: Third Post\n",
            "Processing post 1: First Post\n",
            "Processing post 2: Second Post\n",
            "Processing post 3: Third Post\n",
            "Saving First Post to post_1.txt\n",
            "Saving Second Post to post_2.txt\n",
            "Saving Third Post to post_3.txt\n"
          ]
        }
      ],
      "source": [
        "# Lists and list comprehensions (common in automation)\n",
        "posts = [\n",
        "    {\"id\": 1, \"title\": \"First Post\", \"userId\": 1},\n",
        "    {\"id\": 2, \"title\": \"Second Post\", \"userId\": 1},\n",
        "    {\"id\": 3, \"title\": \"Third Post\", \"userId\": 2},\n",
        "]\n",
        "\n",
        "# List comprehensions for data processing\n",
        "post_titles = [post[\"title\"] for post in posts]\n",
        "user_1_posts = [post for post in posts if post[\"userId\"] == 1]\n",
        "formatted_titles = [title.upper() for title in post_titles if len(title) > 5]\n",
        "\n",
        "print(\"Post titles:\", post_titles)\n",
        "print(\"User 1 posts:\", user_1_posts)\n",
        "print(\"Formatted titles:\", formatted_titles)\n",
        "\n",
        "# Dictionary operations (API responses)\n",
        "api_response = {\n",
        "    \"status\": \"success\",\n",
        "    \"data\": posts,\n",
        "    \"meta\": {\"total\": 3, \"page\": 1}\n",
        "}\n",
        "\n",
        "# Dictionary comprehensions\n",
        "post_lookup = {post[\"id\"]: post[\"title\"] for post in posts}\n",
        "title_lengths = {title: len(title) for title in post_titles}\n",
        "\n",
        "print(\"Post lookup:\", post_lookup)\n",
        "print(\"Title lengths:\", title_lengths)\n",
        "\n",
        "# Sets for unique operations\n",
        "all_user_ids = {post[\"userId\"] for post in posts}\n",
        "unique_words = set(\" \".join(post_titles).lower().split())\n",
        "\n",
        "print(\"Unique user IDs:\", all_user_ids)\n",
        "print(\"Unique words:\", unique_words)\n",
        "\n",
        "# Advanced slicing and unpacking\n",
        "first_post, *rest_posts, last_post = posts if len(posts) >= 2 else (posts[0], [], posts[0])\n",
        "print(f\"First: {first_post['title']}, Last: {last_post['title']}\")\n",
        "\n",
        "# Enumerate and zip (useful for automation loops)\n",
        "for index, post in enumerate(posts, 1):\n",
        "    print(f\"Processing post {index}: {post['title']}\")\n",
        "\n",
        "filenames = [\"post_1.txt\", \"post_2.txt\", \"post_3.txt\"]\n",
        "for post, filename in zip(posts, filenames):\n",
        "    print(f\"Saving {post['title']} to {filename}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Object-Oriented Programming\n",
        "\n",
        "### Classes, Inheritance, and Design Patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base automation bot class\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "class BotStatus(Enum):\n",
        "    IDLE = \"idle\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    ERROR = \"error\"\n",
        "\n",
        "@dataclass\n",
        "class PostData:\n",
        "    \"\"\"Data class for blog posts\"\"\"\n",
        "    id: int\n",
        "    title: str\n",
        "    body: str\n",
        "    user_id: int\n",
        "    \n",
        "    def to_filename(self) -> str:\n",
        "        \"\"\"Convert to safe filename\"\"\"\n",
        "        return f\"post_{self.id}.txt\"\n",
        "    \n",
        "    def format_content(self) -> str:\n",
        "        \"\"\"Format as blog post\"\"\"\n",
        "        return f\"\"\"BLOG POST #{self.id}\n",
        "\n",
        "TITLE: {self.title.title()}\n",
        "\n",
        "CONTENT:\n",
        "{self.body}\n",
        "\n",
        "---\n",
        "User ID: {self.user_id}\n",
        "\"\"\"\n",
        "\n",
        "class BaseBot(ABC):\n",
        "    \"\"\"Abstract base class for automation bots\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.status = BotStatus.IDLE\n",
        "        self.processed_count = 0\n",
        "        self.start_time = None\n",
        "    \n",
        "    @abstractmethod\n",
        "    def process_item(self, item) -> bool:\n",
        "        \"\"\"Process a single item - must be implemented by subclasses\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def start(self):\n",
        "        \"\"\"Start the automation process\"\"\"\n",
        "        self.status = BotStatus.RUNNING\n",
        "        self.start_time = datetime.now()\n",
        "        print(f\"🤖 {self.name} started at {self.start_time}\")\n",
        "    \n",
        "    def finish(self):\n",
        "        \"\"\"Finish the automation process\"\"\"\n",
        "        self.status = BotStatus.COMPLETED\n",
        "        duration = datetime.now() - self.start_time\n",
        "        print(f\"✅ {self.name} completed. Processed {self.processed_count} items in {duration}\")\n",
        "\n",
        "class DesktopBot(BaseBot):\n",
        "    \"\"\"Desktop automation bot implementation\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, output_dir: Path):\n",
        "        super().__init__(name)\n",
        "        self.output_dir = output_dir\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    def process_item(self, post_data: PostData) -> bool:\n",
        "        \"\"\"Process a single post\"\"\"\n",
        "        try:\n",
        "            # Simulate processing time\n",
        "            time.sleep(0.1)\n",
        "            \n",
        "            # Create file\n",
        "            filename = self.output_dir / post_data.to_filename()\n",
        "            content = post_data.format_content()\n",
        "            \n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            self.processed_count += 1\n",
        "            print(f\"📝 Processed post {post_data.id}: {post_data.title[:30]}...\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing post {post_data.id}: {e}\")\n",
        "            return False\n",
        "\n",
        "# Usage example\n",
        "posts_data = [\n",
        "    PostData(1, \"First Post\", \"Content of first post\", 1),\n",
        "    PostData(2, \"Second Post\", \"Content of second post\", 1),\n",
        "    PostData(3, \"Third Post\", \"Content of third post\", 2),\n",
        "]\n",
        "\n",
        "# Create and run bot\n",
        "output_path = Path(\"test_output\")\n",
        "bot = DesktopBot(\"TestBot\", output_path)\n",
        "bot.start()\n",
        "\n",
        "for post in posts_data:\n",
        "    bot.process_item(post)\n",
        "\n",
        "bot.finish()\n",
        "\n",
        "# Demonstrate polymorphism and method overriding\n",
        "class EnhancedBot(DesktopBot):\n",
        "    \"\"\"Enhanced bot with additional features\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, output_dir: Path):\n",
        "        super().__init__(name, output_dir)\n",
        "        self.failed_items = []\n",
        "    \n",
        "    def process_item(self, post_data: PostData) -> bool:\n",
        "        \"\"\"Enhanced processing with retry logic\"\"\"\n",
        "        success = super().process_item(post_data)\n",
        "        if not success:\n",
        "            self.failed_items.append(post_data)\n",
        "        return success\n",
        "    \n",
        "    def retry_failed(self):\n",
        "        \"\"\"Retry failed items\"\"\"\n",
        "        if self.failed_items:\n",
        "            print(f\"🔄 Retrying {len(self.failed_items)} failed items...\")\n",
        "            for item in self.failed_items[:]:  # Copy list to avoid modification during iteration\n",
        "                if self.process_item(item):\n",
        "                    self.failed_items.remove(item)\n",
        "\n",
        "# Property decorators and private methods\n",
        "class ConfigurableBot:\n",
        "    \"\"\"Bot with configuration properties\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self._delay = 0.1\n",
        "        self._max_retries = 3\n",
        "    \n",
        "    @property\n",
        "    def delay(self) -> float:\n",
        "        \"\"\"Get processing delay\"\"\"\n",
        "        return self._delay\n",
        "    \n",
        "    @delay.setter\n",
        "    def delay(self, value: float):\n",
        "        \"\"\"Set processing delay with validation\"\"\"\n",
        "        if value < 0:\n",
        "            raise ValueError(\"Delay cannot be negative\")\n",
        "        self._delay = value\n",
        "    \n",
        "    @property\n",
        "    def max_retries(self) -> int:\n",
        "        return self._max_retries\n",
        "    \n",
        "    def _validate_input(self, data) -> bool:\n",
        "        \"\"\"Private method for input validation\"\"\"\n",
        "        return data is not None and hasattr(data, 'id')\n",
        "\n",
        "# Context managers for resource management\n",
        "class BotContext:\n",
        "    \"\"\"Context manager for bot operations\"\"\"\n",
        "    \n",
        "    def __init__(self, bot: BaseBot):\n",
        "        self.bot = bot\n",
        "    \n",
        "    def __enter__(self):\n",
        "        self.bot.start()\n",
        "        return self.bot\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        if exc_type:\n",
        "            print(f\"❌ Error occurred: {exc_val}\")\n",
        "            self.bot.status = BotStatus.ERROR\n",
        "        else:\n",
        "            self.bot.finish()\n",
        "        return False  # Don't suppress exceptions\n",
        "\n",
        "# Usage with context manager\n",
        "with BotContext(EnhancedBot(\"ContextBot\", Path(\"context_output\"))) as bot:\n",
        "    for post in posts_data[:2]:  # Process first 2 posts\n",
        "        bot.process_item(post)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Error Handling & Exceptions\n",
        "\n",
        "### Try-Catch, Custom Exceptions, and Robust Error Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom exceptions for automation\n",
        "class AutomationError(Exception):\n",
        "    \"\"\"Base exception for automation errors\"\"\"\n",
        "    pass\n",
        "\n",
        "class ApplicationNotFoundError(AutomationError):\n",
        "    \"\"\"Raised when desktop application cannot be found\"\"\"\n",
        "    def __init__(self, app_name: str):\n",
        "        self.app_name = app_name\n",
        "        super().__init__(f\"Application '{app_name}' not found or cannot be launched\")\n",
        "\n",
        "class SaveDialogError(AutomationError):\n",
        "    \"\"\"Raised when save dialog operations fail\"\"\"\n",
        "    def __init__(self, operation: str, details: str = \"\"):\n",
        "        self.operation = operation\n",
        "        self.details = details\n",
        "        super().__init__(f\"Save dialog {operation} failed: {details}\")\n",
        "\n",
        "class APIError(AutomationError):\n",
        "    \"\"\"Raised when API operations fail\"\"\"\n",
        "    def __init__(self, status_code: int, message: str):\n",
        "        self.status_code = status_code\n",
        "        self.message = message\n",
        "        super().__init__(f\"API Error {status_code}: {message}\")\n",
        "\n",
        "# Comprehensive error handling patterns\n",
        "import requests\n",
        "import json\n",
        "from functools import wraps\n",
        "import logging\n",
        "\n",
        "# Setup logging for error tracking\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def retry_on_failure(max_retries: int = 3, delay: float = 1.0):\n",
        "    \"\"\"Decorator for retry logic\"\"\"\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            last_exception = None\n",
        "            \n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except Exception as e:\n",
        "                    last_exception = e\n",
        "                    logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "                    if attempt < max_retries - 1:\n",
        "                        time.sleep(delay)\n",
        "                    \n",
        "            logger.error(f\"All {max_retries} attempts failed\")\n",
        "            raise last_exception\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "class RobustAutomationBot:\n",
        "    \"\"\"Bot with comprehensive error handling\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.error_count = 0\n",
        "        self.success_count = 0\n",
        "    \n",
        "    @retry_on_failure(max_retries=3, delay=0.5)\n",
        "    def fetch_api_data(self, url: str) -> dict:\n",
        "        \"\"\"Fetch data from API with error handling\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raises HTTPError for bad status codes\n",
        "            \n",
        "            data = response.json()\n",
        "            logger.info(f\"✅ Successfully fetched data from {url}\")\n",
        "            return data\n",
        "            \n",
        "        except requests.exceptions.Timeout:\n",
        "            raise APIError(408, \"Request timeout\")\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            raise APIError(0, \"Connection error\")\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            raise APIError(response.status_code, str(e))\n",
        "        except json.JSONDecodeError:\n",
        "            raise APIError(200, \"Invalid JSON response\")\n",
        "    \n",
        "    def safe_file_operation(self, filepath: Path, content: str) -> bool:\n",
        "        \"\"\"Safely write file with error handling\"\"\"\n",
        "        try:\n",
        "            # Ensure directory exists\n",
        "            filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            # Write file with backup\n",
        "            backup_path = filepath.with_suffix(filepath.suffix + '.bak')\n",
        "            \n",
        "            # Create backup if file exists\n",
        "            if filepath.exists():\n",
        "                filepath.rename(backup_path)\n",
        "            \n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            # Remove backup on success\n",
        "            if backup_path.exists():\n",
        "                backup_path.unlink()\n",
        "            \n",
        "            logger.info(f\"✅ File saved successfully: {filepath}\")\n",
        "            self.success_count += 1\n",
        "            return True\n",
        "            \n",
        "        except PermissionError:\n",
        "            logger.error(f\"❌ Permission denied: {filepath}\")\n",
        "            self.error_count += 1\n",
        "            return False\n",
        "        except OSError as e:\n",
        "            logger.error(f\"❌ OS error: {e}\")\n",
        "            self.error_count += 1\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Unexpected error: {e}\")\n",
        "            self.error_count += 1\n",
        "            return False\n",
        "    \n",
        "    def process_with_validation(self, data: dict) -> bool:\n",
        "        \"\"\"Process data with comprehensive validation\"\"\"\n",
        "        try:\n",
        "            # Input validation\n",
        "            required_fields = ['id', 'title', 'body', 'userId']\n",
        "            missing_fields = [field for field in required_fields if field not in data]\n",
        "            \n",
        "            if missing_fields:\n",
        "                raise ValueError(f\"Missing required fields: {missing_fields}\")\n",
        "            \n",
        "            # Type validation\n",
        "            if not isinstance(data['id'], int) or data['id'] <= 0:\n",
        "                raise ValueError(f\"Invalid ID: {data['id']}\")\n",
        "            \n",
        "            if not isinstance(data['title'], str) or not data['title'].strip():\n",
        "                raise ValueError(f\"Invalid title: {data['title']}\")\n",
        "            \n",
        "            # Process the data\n",
        "            filename = f\"post_{data['id']}.txt\"\n",
        "            content = f\"\"\"BLOG POST #{data['id']}\n",
        "\n",
        "TITLE: {data['title']}\n",
        "\n",
        "CONTENT:\n",
        "{data['body']}\n",
        "\n",
        "---\n",
        "User ID: {data['userId']}\n",
        "\"\"\"\n",
        "            \n",
        "            filepath = Path(\"validated_output\") / filename\n",
        "            return self.safe_file_operation(filepath, content)\n",
        "            \n",
        "        except ValueError as e:\n",
        "            logger.error(f\"❌ Validation error: {e}\")\n",
        "            self.error_count += 1\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Processing error: {e}\")\n",
        "            self.error_count += 1\n",
        "            return False\n",
        "    \n",
        "    def get_status_report(self) -> dict:\n",
        "        \"\"\"Get detailed status report\"\"\"\n",
        "        total = self.success_count + self.error_count\n",
        "        success_rate = (self.success_count / total * 100) if total > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            \"total_processed\": total,\n",
        "            \"successful\": self.success_count,\n",
        "            \"failed\": self.error_count,\n",
        "            \"success_rate\": f\"{success_rate:.1f}%\"\n",
        "        }\n",
        "\n",
        "# Test error handling\n",
        "bot = RobustAutomationBot(\"ErrorBot\")\n",
        "\n",
        "# Test with valid data\n",
        "valid_data = {\"id\": 1, \"title\": \"Test Post\", \"body\": \"Content\", \"userId\": 1}\n",
        "bot.process_with_validation(valid_data)\n",
        "\n",
        "# Test with invalid data\n",
        "invalid_data = {\"id\": -1, \"title\": \"\", \"body\": \"Content\"}  # Missing userId, invalid id and title\n",
        "bot.process_with_validation(invalid_data)\n",
        "\n",
        "# Test API with invalid URL\n",
        "try:\n",
        "    bot.fetch_api_data(\"https://invalid-url-that-does-not-exist.com\")\n",
        "except APIError as e:\n",
        "    print(f\"Caught API error: {e}\")\n",
        "\n",
        "print(\"Status report:\", bot.get_status_report())\n",
        "\n",
        "# Context manager for error handling\n",
        "class ErrorHandlingContext:\n",
        "    \"\"\"Context manager that handles and logs errors\"\"\"\n",
        "    \n",
        "    def __init__(self, operation_name: str):\n",
        "        self.operation_name = operation_name\n",
        "        self.start_time = None\n",
        "    \n",
        "    def __enter__(self):\n",
        "        self.start_time = datetime.now()\n",
        "        logger.info(f\"🚀 Starting {self.operation_name}\")\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        duration = datetime.now() - self.start_time\n",
        "        \n",
        "        if exc_type is None:\n",
        "            logger.info(f\"✅ {self.operation_name} completed successfully in {duration}\")\n",
        "        else:\n",
        "            logger.error(f\"❌ {self.operation_name} failed after {duration}: {exc_val}\")\n",
        "            \n",
        "            # Log different exception types differently\n",
        "            if isinstance(exc_val, AutomationError):\n",
        "                logger.error(f\"Automation error details: {exc_val}\")\n",
        "            elif isinstance(exc_val, (requests.RequestException, APIError)):\n",
        "                logger.error(f\"Network/API error: {exc_val}\")\n",
        "            else:\n",
        "                logger.error(f\"Unexpected error: {exc_val}\")\n",
        "        \n",
        "        return False  # Don't suppress exceptions\n",
        "\n",
        "# Usage example\n",
        "with ErrorHandlingContext(\"File Processing\"):\n",
        "    # This will succeed\n",
        "    bot.safe_file_operation(Path(\"test_file.txt\"), \"Test content\")\n",
        "\n",
        "try:\n",
        "    with ErrorHandlingContext(\"Risky Operation\"):\n",
        "        raise ValueError(\"Something went wrong!\")\n",
        "except ValueError:\n",
        "    print(\"Exception was properly logged and re-raised\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. File I/O & Path Management\n",
        "\n",
        "### Modern Path Handling, File Operations, and Directory Management\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modern path handling with pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Generator, Iterator\n",
        "import os\n",
        "\n",
        "# Path operations (essential for desktop automation)\n",
        "def demo_path_operations():\n",
        "    \"\"\"Demonstrate modern path handling\"\"\"\n",
        "    \n",
        "    # Create paths cross-platform\n",
        "    home = Path.home()\n",
        "    desktop = home / \"Desktop\"\n",
        "    project_dir = desktop / \"tjm-project\"\n",
        "    \n",
        "    print(f\"Home: {home}\")\n",
        "    print(f\"Desktop: {desktop}\")\n",
        "    print(f\"Project dir: {project_dir}\")\n",
        "    \n",
        "    # Path properties and methods\n",
        "    sample_file = project_dir / \"post_1.txt\"\n",
        "    print(f\"Filename: {sample_file.name}\")\n",
        "    print(f\"Stem: {sample_file.stem}\")\n",
        "    print(f\"Suffix: {sample_file.suffix}\")\n",
        "    print(f\"Parent: {sample_file.parent}\")\n",
        "    print(f\"Parts: {sample_file.parts}\")\n",
        "    print(f\"Is absolute: {sample_file.is_absolute()}\")\n",
        "    \n",
        "    # Path manipulation\n",
        "    backup_file = sample_file.with_suffix('.bak')\n",
        "    numbered_file = sample_file.with_stem(f\"{sample_file.stem}_v2\")\n",
        "    \n",
        "    print(f\"Backup file: {backup_file}\")\n",
        "    print(f\"Numbered file: {numbered_file}\")\n",
        "    \n",
        "    return project_dir\n",
        "\n",
        "# File operations with context managers\n",
        "class FileManager:\n",
        "    \"\"\"Comprehensive file management for automation\"\"\"\n",
        "    \n",
        "    def __init__(self, base_dir: Path):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.ensure_directory()\n",
        "    \n",
        "    def ensure_directory(self):\n",
        "        \"\"\"Create directory if it doesn't exist\"\"\"\n",
        "        self.base_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"📁 Directory ensured: {self.base_dir}\")\n",
        "    \n",
        "    def write_text_file(self, filename: str, content: str, encoding: str = 'utf-8') -> bool:\n",
        "        \"\"\"Write text file with error handling\"\"\"\n",
        "        try:\n",
        "            filepath = self.base_dir / filename\n",
        "            with open(filepath, 'w', encoding=encoding) as f:\n",
        "                f.write(content)\n",
        "            print(f\"✅ File written: {filepath}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error writing file: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def read_text_file(self, filename: str, encoding: str = 'utf-8') -> Optional[str]:\n",
        "        \"\"\"Read text file with error handling\"\"\"\n",
        "        try:\n",
        "            filepath = self.base_dir / filename\n",
        "            if not filepath.exists():\n",
        "                print(f\"⚠️ File not found: {filepath}\")\n",
        "                return None\n",
        "                \n",
        "            with open(filepath, 'r', encoding=encoding) as f:\n",
        "                content = f.read()\n",
        "            print(f\"✅ File read: {filepath}\")\n",
        "            return content\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading file: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def write_json_file(self, filename: str, data: dict) -> bool:\n",
        "        \"\"\"Write JSON file\"\"\"\n",
        "        try:\n",
        "            filepath = self.base_dir / filename\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"✅ JSON file written: {filepath}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error writing JSON: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def read_json_file(self, filename: str) -> Optional[dict]:\n",
        "        \"\"\"Read JSON file\"\"\"\n",
        "        try:\n",
        "            filepath = self.base_dir / filename\n",
        "            if not filepath.exists():\n",
        "                return None\n",
        "                \n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            print(f\"✅ JSON file read: {filepath}\")\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading JSON: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def write_csv_file(self, filename: str, data: List[dict], fieldnames: List[str]) -> bool:\n",
        "        \"\"\"Write CSV file\"\"\"\n",
        "        try:\n",
        "            filepath = self.base_dir / filename\n",
        "            with open(filepath, 'w', newline='', encoding='utf-8') as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                writer.writerows(data)\n",
        "            print(f\"✅ CSV file written: {filepath}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error writing CSV: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def backup_file(self, filename: str) -> bool:\n",
        "        \"\"\"Create backup of file\"\"\"\n",
        "        try:\n",
        "            original = self.base_dir / filename\n",
        "            if not original.exists():\n",
        "                print(f\"⚠️ Original file not found: {original}\")\n",
        "                return False\n",
        "            \n",
        "            backup = original.with_suffix(original.suffix + '.bak')\n",
        "            shutil.copy2(original, backup)\n",
        "            print(f\"✅ Backup created: {backup}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error creating backup: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def list_files(self, pattern: str = \"*\") -> List[Path]:\n",
        "        \"\"\"List files matching pattern\"\"\"\n",
        "        files = list(self.base_dir.glob(pattern))\n",
        "        print(f\"📄 Found {len(files)} files matching '{pattern}'\")\n",
        "        return files\n",
        "    \n",
        "    def cleanup_old_files(self, days: int = 7) -> int:\n",
        "        \"\"\"Remove files older than specified days\"\"\"\n",
        "        cutoff_time = datetime.now() - timedelta(days=days)\n",
        "        removed_count = 0\n",
        "        \n",
        "        for file in self.base_dir.iterdir():\n",
        "            if file.is_file():\n",
        "                file_time = datetime.fromtimestamp(file.stat().st_mtime)\n",
        "                if file_time < cutoff_time:\n",
        "                    try:\n",
        "                        file.unlink()\n",
        "                        print(f\"🗑️ Removed old file: {file}\")\n",
        "                        removed_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"❌ Error removing file {file}: {e}\")\n",
        "        \n",
        "        return removed_count\n",
        "\n",
        "# File iteration and processing\n",
        "def process_files_generator(directory: Path, pattern: str = \"*.txt\") -> Generator[Tuple[Path, str], None, None]:\n",
        "    \"\"\"Generator that yields file paths and content\"\"\"\n",
        "    for filepath in directory.glob(pattern):\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            yield filepath, content\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading {filepath}: {e}\")\n",
        "\n",
        "def batch_process_files(directory: Path, processor_func, batch_size: int = 5):\n",
        "    \"\"\"Process files in batches\"\"\"\n",
        "    files = list(directory.glob(\"*.txt\"))\n",
        "    \n",
        "    for i in range(0, len(files), batch_size):\n",
        "        batch = files[i:i + batch_size]\n",
        "        print(f\"Processing batch {i//batch_size + 1}: {len(batch)} files\")\n",
        "        \n",
        "        for file in batch:\n",
        "            try:\n",
        "                processor_func(file)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error processing {file}: {e}\")\n",
        "\n",
        "# Temporary files for testing\n",
        "class TempFileManager:\n",
        "    \"\"\"Manage temporary files for testing automation\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.temp_dir = Path(tempfile.mkdtemp(prefix=\"automation_test_\"))\n",
        "        print(f\"📁 Created temp directory: {self.temp_dir}\")\n",
        "    \n",
        "    def create_test_files(self, count: int = 5) -> List[Path]:\n",
        "        \"\"\"Create test files for automation testing\"\"\"\n",
        "        files = []\n",
        "        for i in range(1, count + 1):\n",
        "            content = f\"\"\"BLOG POST #{i}\n",
        "\n",
        "TITLE: Test Post {i}\n",
        "\n",
        "CONTENT:\n",
        "This is the content of test post number {i}.\n",
        "It contains multiple paragraphs.\n",
        "\n",
        "This is the second paragraph with some sample text.\n",
        "\n",
        "---\n",
        "Post ID: {i}\n",
        "User ID: {i % 3 + 1}\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "            filepath = self.temp_dir / f\"post_{i}.txt\"\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            files.append(filepath)\n",
        "        \n",
        "        print(f\"✅ Created {len(files)} test files\")\n",
        "        return files\n",
        "    \n",
        "    def cleanup(self):\n",
        "        \"\"\"Remove temporary directory\"\"\"\n",
        "        try:\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "            print(f\"🗑️ Cleaned up temp directory: {self.temp_dir}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error cleaning up: {e}\")\n",
        "\n",
        "# Demo usage\n",
        "print(\"=== Path Operations Demo ===\")\n",
        "project_dir = demo_path_operations()\n",
        "\n",
        "print(\"\\n=== File Manager Demo ===\")\n",
        "file_manager = FileManager(\"demo_files\")\n",
        "\n",
        "# Write different file types\n",
        "sample_data = {\"posts\": [{\"id\": 1, \"title\": \"Sample\", \"content\": \"Test\"}]}\n",
        "file_manager.write_json_file(\"config.json\", sample_data)\n",
        "\n",
        "blog_content = \"\"\"BLOG POST #1\n",
        "\n",
        "TITLE: Sample Blog Post\n",
        "\n",
        "CONTENT:\n",
        "This is a sample blog post content.\n",
        "\"\"\"\n",
        "file_manager.write_text_file(\"sample_post.txt\", blog_content)\n",
        "\n",
        "# CSV example\n",
        "csv_data = [\n",
        "    {\"post_id\": 1, \"title\": \"First Post\", \"status\": \"published\"},\n",
        "    {\"post_id\": 2, \"title\": \"Second Post\", \"status\": \"draft\"}\n",
        "]\n",
        "file_manager.write_csv_file(\"posts.csv\", csv_data, [\"post_id\", \"title\", \"status\"])\n",
        "\n",
        "# List and backup files\n",
        "files = file_manager.list_files(\"*.txt\")\n",
        "if files:\n",
        "    file_manager.backup_file(\"sample_post.txt\")\n",
        "\n",
        "print(\"\\n=== Temporary Files Demo ===\")\n",
        "temp_manager = TempFileManager()\n",
        "test_files = temp_manager.create_test_files(3)\n",
        "\n",
        "# Process files with generator\n",
        "print(\"\\n=== File Processing Demo ===\")\n",
        "for filepath, content in process_files_generator(temp_manager.temp_dir):\n",
        "    print(f\"📄 {filepath.name}: {len(content)} characters\")\n",
        "\n",
        "# Clean up\n",
        "temp_manager.cleanup()\n",
        "\n",
        "# Advanced file operations\n",
        "print(\"\\n=== Advanced File Operations ===\")\n",
        "\n",
        "def safe_atomic_write(filepath: Path, content: str) -> bool:\n",
        "    \"\"\"Atomic write operation (write to temp, then rename)\"\"\"\n",
        "    temp_path = filepath.with_suffix(filepath.suffix + '.tmp')\n",
        "    try:\n",
        "        with open(temp_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "        temp_path.replace(filepath)  # Atomic rename\n",
        "        print(f\"✅ Atomic write successful: {filepath}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        if temp_path.exists():\n",
        "            temp_path.unlink()\n",
        "        print(f\"❌ Atomic write failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# File watching simulation\n",
        "def monitor_directory_changes(directory: Path, duration: int = 5):\n",
        "    \"\"\"Monitor directory for changes (simplified)\"\"\"\n",
        "    initial_files = set(directory.glob(\"*\"))\n",
        "    print(f\"👀 Monitoring {directory} for {duration} seconds...\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < duration:\n",
        "        current_files = set(directory.glob(\"*\"))\n",
        "        \n",
        "        new_files = current_files - initial_files\n",
        "        deleted_files = initial_files - current_files\n",
        "        \n",
        "        if new_files:\n",
        "            print(f\"📄 New files: {[f.name for f in new_files]}\")\n",
        "        if deleted_files:\n",
        "            print(f\"🗑️ Deleted files: {[f.name for f in deleted_files]}\")\n",
        "        \n",
        "        initial_files = current_files\n",
        "        time.sleep(1)\n",
        "    \n",
        "    print(\"👀 Monitoring stopped\")\n",
        "\n",
        "# Test atomic write\n",
        "test_dir = Path(\"atomic_test\")\n",
        "test_dir.mkdir(exist_ok=True)\n",
        "safe_atomic_write(test_dir / \"atomic_file.txt\", \"This was written atomically!\")\n",
        "\n",
        "# Cleanup test directory\n",
        "try:\n",
        "    shutil.rmtree(test_dir)\n",
        "    shutil.rmtree(\"demo_files\")\n",
        "except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. APIs & HTTP Requests\n",
        "\n",
        "### Requests Library, Error Handling, and API Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive API handling for automation\n",
        "import requests\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "from requests.adapters import HTTPAdapter\n",
        "from requests.packages.urllib3.util.retry import Retry\n",
        "\n",
        "class APIClient:\n",
        "    \"\"\"Robust API client for automation tasks\"\"\"\n",
        "    \n",
        "    def __init__(self, base_url: str, timeout: int = 10):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.timeout = timeout\n",
        "        self.session = self._create_session()\n",
        "    \n",
        "    def _create_session(self) -> requests.Session:\n",
        "        \"\"\"Create session with retry strategy\"\"\"\n",
        "        session = requests.Session()\n",
        "        \n",
        "        # Retry strategy\n",
        "        retry_strategy = Retry(\n",
        "            total=3,\n",
        "            backoff_factor=1,\n",
        "            status_forcelist=[429, 500, 502, 503, 504],\n",
        "            method_whitelist=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
        "        )\n",
        "        \n",
        "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
        "        session.mount(\"http://\", adapter)\n",
        "        session.mount(\"https://\", adapter)\n",
        "        \n",
        "        # Default headers\n",
        "        session.headers.update({\n",
        "            'User-Agent': 'Python-Automation-Bot/1.0',\n",
        "            'Accept': 'application/json',\n",
        "            'Content-Type': 'application/json'\n",
        "        })\n",
        "        \n",
        "        return session\n",
        "    \n",
        "    def get(self, endpoint: str, params: Optional[dict] = None) -> dict:\n",
        "        \"\"\"GET request with error handling\"\"\"\n",
        "        url = urljoin(self.base_url + '/', endpoint.lstrip('/'))\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=self.timeout)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.Timeout:\n",
        "            raise APIError(408, f\"Request timeout for {url}\")\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            raise APIError(0, f\"Connection error for {url}\")\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            raise APIError(response.status_code, f\"HTTP error: {e}\")\n",
        "        except json.JSONDecodeError:\n",
        "            raise APIError(200, f\"Invalid JSON response from {url}\")\n",
        "    \n",
        "    def post(self, endpoint: str, data: dict) -> dict:\n",
        "        \"\"\"POST request with error handling\"\"\"\n",
        "        url = urljoin(self.base_url + '/', endpoint.lstrip('/'))\n",
        "        \n",
        "        try:\n",
        "            response = self.session.post(url, json=data, timeout=self.timeout)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise APIError(getattr(e.response, 'status_code', 0), str(e))\n",
        "\n",
        "class JSONPlaceholderClient(APIClient):\n",
        "    \"\"\"Specific client for JSONPlaceholder API\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__(\"https://jsonplaceholder.typicode.com\")\n",
        "    \n",
        "    def get_posts(self, limit: Optional[int] = None, user_id: Optional[int] = None) -> List[dict]:\n",
        "        \"\"\"Get posts with optional filtering\"\"\"\n",
        "        params = {}\n",
        "        if limit:\n",
        "            params['_limit'] = limit\n",
        "        if user_id:\n",
        "            params['userId'] = user_id\n",
        "        \n",
        "        return self.get('posts', params)\n",
        "    \n",
        "    def get_post(self, post_id: int) -> dict:\n",
        "        \"\"\"Get single post\"\"\"\n",
        "        return self.get(f'posts/{post_id}')\n",
        "    \n",
        "    def get_users(self) -> List[dict]:\n",
        "        \"\"\"Get all users\"\"\"\n",
        "        return self.get('users')\n",
        "    \n",
        "    def get_comments(self, post_id: Optional[int] = None) -> List[dict]:\n",
        "        \"\"\"Get comments, optionally for specific post\"\"\"\n",
        "        params = {'postId': post_id} if post_id else {}\n",
        "        return self.get('comments', params)\n",
        "\n",
        "# Advanced request patterns\n",
        "class BatchAPIClient:\n",
        "    \"\"\"Handle batch API requests efficiently\"\"\"\n",
        "    \n",
        "    def __init__(self, client: APIClient):\n",
        "        self.client = client\n",
        "    \n",
        "    def fetch_posts_batch(self, post_ids: List[int]) -> Dict[int, dict]:\n",
        "        \"\"\"Fetch multiple posts, handling failures gracefully\"\"\"\n",
        "        results = {}\n",
        "        failed_ids = []\n",
        "        \n",
        "        for post_id in post_ids:\n",
        "            try:\n",
        "                post = self.client.get(f'posts/{post_id}')\n",
        "                results[post_id] = post\n",
        "                print(f\"✅ Fetched post {post_id}\")\n",
        "            except APIError as e:\n",
        "                failed_ids.append(post_id)\n",
        "                print(f\"❌ Failed to fetch post {post_id}: {e}\")\n",
        "            except Exception as e:\n",
        "                failed_ids.append(post_id)\n",
        "                print(f\"❌ Unexpected error for post {post_id}: {e}\")\n",
        "        \n",
        "        return results, failed_ids\n",
        "    \n",
        "    def fetch_with_dependencies(self, post_id: int) -> dict:\n",
        "        \"\"\"Fetch post with related data (user, comments)\"\"\"\n",
        "        try:\n",
        "            # Fetch post\n",
        "            post = self.client.get(f'posts/{post_id}')\n",
        "            \n",
        "            # Fetch user info\n",
        "            user = self.client.get(f'users/{post[\"userId\"]}')\n",
        "            \n",
        "            # Fetch comments\n",
        "            comments = self.client.get('comments', {'postId': post_id})\n",
        "            \n",
        "            return {\n",
        "                'post': post,\n",
        "                'author': user,\n",
        "                'comments': comments,\n",
        "                'meta': {\n",
        "                    'fetched_at': datetime.now().isoformat(),\n",
        "                    'comment_count': len(comments)\n",
        "                }\n",
        "            }\n",
        "        except APIError as e:\n",
        "            print(f\"❌ Error fetching dependencies for post {post_id}: {e}\")\n",
        "            return {}\n",
        "\n",
        "# Caching and rate limiting\n",
        "from functools import lru_cache\n",
        "import hashlib\n",
        "\n",
        "class CachedAPIClient:\n",
        "    \"\"\"API client with caching capabilities\"\"\"\n",
        "    \n",
        "    def __init__(self, client: APIClient, cache_duration: int = 300):\n",
        "        self.client = client\n",
        "        self.cache_duration = cache_duration\n",
        "        self._cache = {}\n",
        "    \n",
        "    def _cache_key(self, method: str, endpoint: str, params: dict = None) -> str:\n",
        "        \"\"\"Generate cache key\"\"\"\n",
        "        cache_data = f\"{method}:{endpoint}:{params or {}}\"\n",
        "        return hashlib.md5(cache_data.encode()).hexdigest()\n",
        "    \n",
        "    def _is_cache_valid(self, timestamp: datetime) -> bool:\n",
        "        \"\"\"Check if cache entry is still valid\"\"\"\n",
        "        return (datetime.now() - timestamp).seconds < self.cache_duration\n",
        "    \n",
        "    def get_cached(self, endpoint: str, params: dict = None) -> dict:\n",
        "        \"\"\"Get with caching\"\"\"\n",
        "        cache_key = self._cache_key('GET', endpoint, params)\n",
        "        \n",
        "        # Check cache\n",
        "        if cache_key in self._cache:\n",
        "            data, timestamp = self._cache[cache_key]\n",
        "            if self._is_cache_valid(timestamp):\n",
        "                print(f\"🎯 Cache hit for {endpoint}\")\n",
        "                return data\n",
        "        \n",
        "        # Fetch from API\n",
        "        print(f\"🌐 Fetching from API: {endpoint}\")\n",
        "        data = self.client.get(endpoint, params)\n",
        "        \n",
        "        # Cache result\n",
        "        self._cache[cache_key] = (data, datetime.now())\n",
        "        return data\n",
        "\n",
        "# Demo usage\n",
        "print(\"=== Basic API Client Demo ===\")\n",
        "client = JSONPlaceholderClient()\n",
        "\n",
        "try:\n",
        "    # Fetch posts\n",
        "    posts = client.get_posts(limit=3)\n",
        "    print(f\"📋 Fetched {len(posts)} posts\")\n",
        "    \n",
        "    for post in posts:\n",
        "        print(f\"  - Post {post['id']}: {post['title'][:50]}...\")\n",
        "    \n",
        "    # Fetch specific post\n",
        "    single_post = client.get_post(1)\n",
        "    print(f\"📄 Single post: {single_post['title']}\")\n",
        "    \n",
        "    # Fetch users\n",
        "    users = client.get_users()\n",
        "    print(f\"👥 Found {len(users)} users\")\n",
        "    \n",
        "except APIError as e:\n",
        "    print(f\"❌ API Error: {e}\")\n",
        "\n",
        "print(\"\\n=== Batch Processing Demo ===\")\n",
        "batch_client = BatchAPIClient(client)\n",
        "post_ids = [1, 2, 3, 999]  # 999 doesn't exist\n",
        "results, failed = batch_client.fetch_posts_batch(post_ids)\n",
        "print(f\"✅ Successfully fetched: {list(results.keys())}\")\n",
        "print(f\"❌ Failed: {failed}\")\n",
        "\n",
        "print(\"\\n=== Dependencies Demo ===\")\n",
        "rich_post = batch_client.fetch_with_dependencies(1)\n",
        "if rich_post:\n",
        "    print(f\"📄 Post: {rich_post['post']['title']}\")\n",
        "    print(f\"👤 Author: {rich_post['author']['name']}\")\n",
        "    print(f\"💬 Comments: {rich_post['meta']['comment_count']}\")\n",
        "\n",
        "print(\"\\n=== Caching Demo ===\")\n",
        "cached_client = CachedAPIClient(client, cache_duration=60)\n",
        "\n",
        "# First call - will fetch from API\n",
        "posts1 = cached_client.get_cached('posts', {'_limit': 2})\n",
        "print(f\"First call: {len(posts1)} posts\")\n",
        "\n",
        "# Second call - will use cache\n",
        "posts2 = cached_client.get_cached('posts', {'_limit': 2})\n",
        "print(f\"Second call: {len(posts2)} posts\")\n",
        "\n",
        "# API response validation\n",
        "def validate_post_data(post: dict) -> bool:\n",
        "    \"\"\"Validate post data structure\"\"\"\n",
        "    required_fields = ['id', 'title', 'body', 'userId']\n",
        "    \n",
        "    # Check required fields\n",
        "    if not all(field in post for field in required_fields):\n",
        "        return False\n",
        "    \n",
        "    # Type validation\n",
        "    if not isinstance(post['id'], int) or post['id'] <= 0:\n",
        "        return False\n",
        "    \n",
        "    if not isinstance(post['title'], str) or not post['title'].strip():\n",
        "        return False\n",
        "    \n",
        "    if not isinstance(post['body'], str):\n",
        "        return False\n",
        "    \n",
        "    if not isinstance(post['userId'], int) or post['userId'] <= 0:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "# Test validation\n",
        "for post in posts[:2]:\n",
        "    is_valid = validate_post_data(post)\n",
        "    print(f\"Post {post['id']} validation: {'✅ Valid' if is_valid else '❌ Invalid'}\")\n",
        "\n",
        "# Rate limiting simulation\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "class RateLimitedClient:\n",
        "    \"\"\"Client with rate limiting\"\"\"\n",
        "    \n",
        "    def __init__(self, client: APIClient, requests_per_minute: int = 60):\n",
        "        self.client = client\n",
        "        self.requests_per_minute = requests_per_minute\n",
        "        self.request_times = deque()\n",
        "    \n",
        "    def _can_make_request(self) -> bool:\n",
        "        \"\"\"Check if we can make a request without exceeding rate limit\"\"\"\n",
        "        now = time.time()\n",
        "        # Remove requests older than 1 minute\n",
        "        while self.request_times and now - self.request_times[0] > 60:\n",
        "            self.request_times.popleft()\n",
        "        \n",
        "        return len(self.request_times) < self.requests_per_minute\n",
        "    \n",
        "    def _wait_for_rate_limit(self):\n",
        "        \"\"\"Wait until we can make another request\"\"\"\n",
        "        while not self._can_make_request():\n",
        "            print(\"⏳ Rate limit reached, waiting...\")\n",
        "            time.sleep(1)\n",
        "    \n",
        "    def get(self, endpoint: str, params: dict = None) -> dict:\n",
        "        \"\"\"GET with rate limiting\"\"\"\n",
        "        self._wait_for_rate_limit()\n",
        "        self.request_times.append(time.time())\n",
        "        return self.client.get(endpoint, params)\n",
        "\n",
        "print(\"\\n=== Rate Limiting Demo ===\")\n",
        "rate_limited = RateLimitedClient(client, requests_per_minute=5)  # Very low limit for demo\n",
        "\n",
        "# This would normally trigger rate limiting with many requests\n",
        "try:\n",
        "    for i in range(3):\n",
        "        post = rate_limited.get(f'posts/{i+1}')\n",
        "        print(f\"📄 Rate-limited fetch {i+1}: {post['title'][:30]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Rate limiting error: {e}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Desktop Automation (PyAutoGUI)\n",
        "\n",
        "### GUI Automation, Keyboard/Mouse Control, and Cross-Platform Considerations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Desktop automation patterns and best practices\n",
        "import pyautogui\n",
        "import subprocess\n",
        "import platform\n",
        "from typing import Callable, Any\n",
        "import functools\n",
        "\n",
        "# Configure PyAutoGUI for safety and reliability\n",
        "pyautogui.PAUSE = 0.1  # Small pause between actions\n",
        "pyautogui.FAILSAFE = True  # Move mouse to top-left to stop\n",
        "\n",
        "class AutomationSafety:\n",
        "    \"\"\"Safety wrapper for automation operations\"\"\"\n",
        "    \n",
        "    def __init__(self, pause_time: float = 0.1):\n",
        "        self.original_pause = pyautogui.PAUSE\n",
        "        pyautogui.PAUSE = pause_time\n",
        "        \n",
        "    def __enter__(self):\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        pyautogui.PAUSE = self.original_pause\n",
        "\n",
        "def safe_automation(func: Callable) -> Callable:\n",
        "    \"\"\"Decorator for safe automation operations\"\"\"\n",
        "    @functools.wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            with AutomationSafety():\n",
        "                return func(*args, **kwargs)\n",
        "        except pyautogui.FailSafeException:\n",
        "            print(\"🛑 Automation stopped by failsafe (mouse moved to corner)\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Automation error: {e}\")\n",
        "            return False\n",
        "    return wrapper\n",
        "\n",
        "class CrossPlatformAutomation:\n",
        "    \"\"\"Cross-platform desktop automation handler\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.os_type = platform.system()\n",
        "        self.shortcuts = self._get_platform_shortcuts()\n",
        "    \n",
        "    def _get_platform_shortcuts(self) -> dict:\n",
        "        \"\"\"Get platform-specific keyboard shortcuts\"\"\"\n",
        "        if self.os_type == \"Darwin\":  # macOS\n",
        "            return {\n",
        "                'new': ['cmd', 'n'],\n",
        "                'save': ['cmd', 's'],\n",
        "                'save_as': ['cmd', 'shift', 's'],\n",
        "                'select_all': ['cmd', 'a'],\n",
        "                'copy': ['cmd', 'c'],\n",
        "                'paste': ['cmd', 'v'],\n",
        "                'close': ['cmd', 'w'],\n",
        "                'quit': ['cmd', 'q'],\n",
        "                'plain_text': ['cmd', 'shift', 't']\n",
        "            }\n",
        "        elif self.os_type == \"Windows\":\n",
        "            return {\n",
        "                'new': ['ctrl', 'n'],\n",
        "                'save': ['ctrl', 's'],\n",
        "                'save_as': ['ctrl', 'shift', 's'],\n",
        "                'select_all': ['ctrl', 'a'],\n",
        "                'copy': ['ctrl', 'c'],\n",
        "                'paste': ['ctrl', 'v'],\n",
        "                'close': ['alt', 'f4'],\n",
        "                'quit': ['alt', 'f4'],\n",
        "                'plain_text': []  # Not applicable for Notepad\n",
        "            }\n",
        "        else:  # Linux\n",
        "            return {\n",
        "                'new': ['ctrl', 'n'],\n",
        "                'save': ['ctrl', 's'],\n",
        "                'save_as': ['ctrl', 'shift', 's'],\n",
        "                'select_all': ['ctrl', 'a'],\n",
        "                'copy': ['ctrl', 'c'],\n",
        "                'paste': ['ctrl', 'v'],\n",
        "                'close': ['alt', 'f4'],\n",
        "                'quit': ['ctrl', 'q'],\n",
        "                'plain_text': []\n",
        "            }\n",
        "    \n",
        "    @safe_automation\n",
        "    def execute_shortcut(self, action: str) -> bool:\n",
        "        \"\"\"Execute platform-specific keyboard shortcut\"\"\"\n",
        "        if action not in self.shortcuts:\n",
        "            print(f\"❌ Unknown action: {action}\")\n",
        "            return False\n",
        "        \n",
        "        keys = self.shortcuts[action]\n",
        "        if not keys:\n",
        "            print(f\"⚠️ Action '{action}' not supported on {self.os_type}\")\n",
        "            return True  # Not an error, just not applicable\n",
        "        \n",
        "        try:\n",
        "            if self.os_type == \"Darwin\" and 'cmd' in keys:\n",
        "                # Use .hold() method for macOS command key\n",
        "                with pyautogui.hold(['command']):\n",
        "                    time.sleep(0.1)\n",
        "                    for key in keys[1:]:  # Skip 'cmd'\n",
        "                        pyautogui.press(key)\n",
        "            else:\n",
        "                pyautogui.hotkey(*keys)\n",
        "            \n",
        "            print(f\"✅ Executed {action}: {'+'.join(keys)}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to execute {action}: {e}\")\n",
        "            return False\n",
        "    \n",
        "    @safe_automation\n",
        "    def launch_text_editor(self) -> bool:\n",
        "        \"\"\"Launch appropriate text editor for platform\"\"\"\n",
        "        try:\n",
        "            if self.os_type == \"Darwin\":\n",
        "                subprocess.Popen(['open', '-a', 'TextEdit'])\n",
        "                time.sleep(3)\n",
        "                # Set to plain text mode\n",
        "                self.execute_shortcut('plain_text')\n",
        "            elif self.os_type == \"Windows\":\n",
        "                subprocess.Popen(['notepad.exe'])\n",
        "                time.sleep(2)\n",
        "            else:  # Linux\n",
        "                editors = ['gedit', 'kate', 'mousepad', 'leafpad']\n",
        "                for editor in editors:\n",
        "                    try:\n",
        "                        subprocess.Popen([editor])\n",
        "                        time.sleep(2)\n",
        "                        return True\n",
        "                    except FileNotFoundError:\n",
        "                        continue\n",
        "                return False\n",
        "            \n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to launch text editor: {e}\")\n",
        "            return False\n",
        "\n",
        "class TypewriterEffect:\n",
        "    \"\"\"Advanced text typing with various effects\"\"\"\n",
        "    \n",
        "    def __init__(self, base_delay: float = 0.01):\n",
        "        self.base_delay = base_delay\n",
        "    \n",
        "    @safe_automation\n",
        "    def type_naturally(self, text: str, variation: float = 0.5) -> bool:\n",
        "        \"\"\"Type text with natural human-like variations\"\"\"\n",
        "        import random\n",
        "        \n",
        "        for char in text:\n",
        "            # Add slight random variation to timing\n",
        "            delay = self.base_delay * random.uniform(1 - variation, 1 + variation)\n",
        "            \n",
        "            # Longer pauses for punctuation\n",
        "            if char in '.,!?;:':\n",
        "                delay *= 2\n",
        "            \n",
        "            # Very short pause for spaces\n",
        "            elif char == ' ':\n",
        "                delay *= 0.5\n",
        "            \n",
        "            pyautogui.write(char)\n",
        "            time.sleep(delay)\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    @safe_automation\n",
        "    def type_with_corrections(self, text: str, error_rate: float = 0.02) -> bool:\n",
        "        \"\"\"Type text with occasional 'mistakes' and corrections\"\"\"\n",
        "        import random\n",
        "        import string\n",
        "        \n",
        "        for i, char in enumerate(text):\n",
        "            # Occasionally make a 'mistake'\n",
        "            if random.random() < error_rate:\n",
        "                # Type wrong character\n",
        "                wrong_char = random.choice(string.ascii_lowercase)\n",
        "                pyautogui.write(wrong_char)\n",
        "                time.sleep(self.base_delay * 2)\n",
        "                \n",
        "                # Backspace and correct\n",
        "                pyautogui.press('backspace')\n",
        "                time.sleep(self.base_delay)\n",
        "            \n",
        "            # Type correct character\n",
        "            pyautogui.write(char)\n",
        "            time.sleep(self.base_delay)\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    @safe_automation\n",
        "    def type_progressively_faster(self, text: str, speed_increase: float = 0.9) -> bool:\n",
        "        \"\"\"Type text starting slow and getting faster\"\"\"\n",
        "        words = text.split()\n",
        "        current_delay = self.base_delay * 3  # Start slow\n",
        "        \n",
        "        for word_idx, word in enumerate(words):\n",
        "            for char in word:\n",
        "                pyautogui.write(char)\n",
        "                time.sleep(current_delay)\n",
        "            \n",
        "            # Add space after word (except last word)\n",
        "            if word_idx < len(words) - 1:\n",
        "                pyautogui.write(' ')\n",
        "                time.sleep(current_delay)\n",
        "            \n",
        "            # Increase speed (decrease delay)\n",
        "            current_delay *= speed_increase\n",
        "            current_delay = max(current_delay, self.base_delay * 0.1)  # Minimum delay\n",
        "        \n",
        "        return True\n",
        "\n",
        "class AdvancedFileOperations:\n",
        "    \"\"\"Advanced file dialog and save operations\"\"\"\n",
        "    \n",
        "    def __init__(self, automation: CrossPlatformAutomation):\n",
        "        self.automation = automation\n",
        "    \n",
        "    @safe_automation\n",
        "    def save_with_retry(self, filepath: str, max_retries: int = 3) -> bool:\n",
        "        \"\"\"Save file with multiple retry strategies\"\"\"\n",
        "        for attempt in range(max_retries):\n",
        "            print(f\"💾 Save attempt {attempt + 1}\")\n",
        "            \n",
        "            # Try primary save method\n",
        "            if self._try_save_method(filepath, 'save'):\n",
        "                return True\n",
        "            \n",
        "            time.sleep(1)\n",
        "            \n",
        "            # Try save-as method\n",
        "            if self._try_save_method(filepath, 'save_as'):\n",
        "                return True\n",
        "            \n",
        "            time.sleep(1)\n",
        "        \n",
        "        print(f\"❌ All save attempts failed for {filepath}\")\n",
        "        return False\n",
        "    \n",
        "    def _try_save_method(self, filepath: str, method: str) -> bool:\n",
        "        \"\"\"Try a specific save method\"\"\"\n",
        "        try:\n",
        "            # Open save dialog\n",
        "            if not self.automation.execute_shortcut(method):\n",
        "                return False\n",
        "            \n",
        "            time.sleep(2)  # Wait for dialog\n",
        "            \n",
        "            # Clear existing path\n",
        "            self.automation.execute_shortcut('select_all')\n",
        "            time.sleep(0.5)\n",
        "            \n",
        "            # Type new path character by character for reliability\n",
        "            for char in filepath:\n",
        "                pyautogui.write(char)\n",
        "                time.sleep(0.001)\n",
        "            \n",
        "            time.sleep(1)\n",
        "            \n",
        "            # Confirm save\n",
        "            pyautogui.press('enter')\n",
        "            time.sleep(2)\n",
        "            \n",
        "            # Handle potential overwrite dialog\n",
        "            pyautogui.press('enter')\n",
        "            time.sleep(0.5)\n",
        "            \n",
        "            print(f\"✅ Save successful using {method}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Save method {method} failed: {e}\")\n",
        "            return False\n",
        "\n",
        "# Screen interaction and verification\n",
        "class ScreenVerification:\n",
        "    \"\"\"Verify screen state during automation\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def wait_for_window(title_contains: str, timeout: int = 10) -> bool:\n",
        "        \"\"\"Wait for window with specific title to appear\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        while time.time() - start_time < timeout:\n",
        "            try:\n",
        "                # This is a simplified version - in real implementation,\n",
        "                # you'd use platform-specific window detection\n",
        "                print(f\"🔍 Looking for window containing '{title_contains}'...\")\n",
        "                time.sleep(1)\n",
        "                \n",
        "                # Simulate window found after a few seconds\n",
        "                if time.time() - start_time > 3:\n",
        "                    print(f\"✅ Window found: {title_contains}\")\n",
        "                    return True\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error checking for window: {e}\")\n",
        "                \n",
        "        print(f\"⏰ Timeout waiting for window: {title_contains}\")\n",
        "        return False\n",
        "    \n",
        "    @staticmethod\n",
        "    def capture_screenshot(filename: str = None) -> str:\n",
        "        \"\"\"Capture screenshot for debugging\"\"\"\n",
        "        if filename is None:\n",
        "            filename = f\"automation_screenshot_{int(time.time())}.png\"\n",
        "        \n",
        "        try:\n",
        "            screenshot = pyautogui.screenshot()\n",
        "            screenshot.save(filename)\n",
        "            print(f\"📸 Screenshot saved: {filename}\")\n",
        "            return filename\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to capture screenshot: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# Demo usage\n",
        "print(\"=== Cross-Platform Automation Demo ===\")\n",
        "automation = CrossPlatformAutomation()\n",
        "print(f\"Platform: {automation.os_type}\")\n",
        "print(f\"Available shortcuts: {list(automation.shortcuts.keys())}\")\n",
        "\n",
        "# Test shortcuts (without actually executing them)\n",
        "print(\"\\n=== Shortcut Testing ===\")\n",
        "test_actions = ['new', 'save', 'select_all']\n",
        "for action in test_actions:\n",
        "    if action in automation.shortcuts:\n",
        "        keys = automation.shortcuts[action]\n",
        "        print(f\"{action}: {'+'.join(keys) if keys else 'Not supported'}\")\n",
        "\n",
        "print(\"\\n=== Typewriter Effects Demo ===\")\n",
        "typewriter = TypewriterEffect(base_delay=0.001)  # Very fast for demo\n",
        "\n",
        "# Simulate typing without actually typing\n",
        "print(\"Demo text that would be typed with effects:\")\n",
        "demo_text = \"Hello, this is a test of automated typing!\"\n",
        "print(f\"📝 Natural typing: {demo_text}\")\n",
        "print(f\"📝 With corrections: {demo_text}\")\n",
        "print(f\"📝 Progressive speed: {demo_text}\")\n",
        "\n",
        "print(\"\\n=== File Operations Demo ===\")\n",
        "file_ops = AdvancedFileOperations(automation)\n",
        "print(\"💾 Would attempt to save file with retry logic\")\n",
        "\n",
        "print(\"\\n=== Screen Verification Demo ===\")\n",
        "screen_verify = ScreenVerification()\n",
        "# Simulate window detection\n",
        "print(\"🔍 Simulating window detection...\")\n",
        "\n",
        "# Automation workflow example\n",
        "class AutomationWorkflow:\n",
        "    \"\"\"Complete automation workflow orchestrator\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.automation = CrossPlatformAutomation()\n",
        "        self.typewriter = TypewriterEffect()\n",
        "        self.file_ops = AdvancedFileOperations(self.automation)\n",
        "        self.screen = ScreenVerification()\n",
        "    \n",
        "    def execute_blog_post_workflow(self, post_data: dict, output_path: str) -> bool:\n",
        "        \"\"\"Execute complete blog post creation workflow\"\"\"\n",
        "        try:\n",
        "            print(f\"🚀 Starting workflow for post {post_data['id']}\")\n",
        "            \n",
        "            # 1. Launch text editor\n",
        "            if not self.automation.launch_text_editor():\n",
        "                return False\n",
        "            \n",
        "            # 2. Create new document\n",
        "            self.automation.execute_shortcut('new')\n",
        "            time.sleep(1)\n",
        "            \n",
        "            # 3. Type content with natural timing\n",
        "            content = self._format_blog_content(post_data)\n",
        "            self.typewriter.type_naturally(content)\n",
        "            \n",
        "            # 4. Save document\n",
        "            if not self.file_ops.save_with_retry(output_path):\n",
        "                return False\n",
        "            \n",
        "            # 5. Close editor\n",
        "            self.automation.execute_shortcut('close')\n",
        "            \n",
        "            print(f\"✅ Workflow completed for post {post_data['id']}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Workflow failed: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def _format_blog_content(self, post_data: dict) -> str:\n",
        "        \"\"\"Format post data as blog content\"\"\"\n",
        "        return f\"\"\"BLOG POST #{post_data['id']}\n",
        "\n",
        "TITLE: {post_data['title'].title()}\n",
        "\n",
        "CONTENT:\n",
        "{post_data['body']}\n",
        "\n",
        "---\n",
        "Post ID: {post_data['id']}\n",
        "User ID: {post_data['userId']}\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n=== Complete Workflow Demo ===\")\n",
        "workflow = AutomationWorkflow()\n",
        "\n",
        "# Sample post data\n",
        "sample_post = {\n",
        "    'id': 1,\n",
        "    'title': 'sample blog post',\n",
        "    'body': 'This is the content of the blog post.',\n",
        "    'userId': 1\n",
        "}\n",
        "\n",
        "print(\"🔧 Workflow configured and ready\")\n",
        "print(\"💡 In real execution, this would:\")\n",
        "print(\"  1. Launch text editor\")\n",
        "print(\"  2. Create new document\")\n",
        "print(\"  3. Type formatted content\")\n",
        "print(\"  4. Save to specified path\")\n",
        "print(\"  5. Close editor\")\n",
        "\n",
        "# Error handling patterns for automation\n",
        "class AutomationRecovery:\n",
        "    \"\"\"Handle and recover from automation errors\"\"\"\n",
        "    \n",
        "    def __init__(self, workflow: AutomationWorkflow):\n",
        "        self.workflow = workflow\n",
        "        self.recovery_strategies = {\n",
        "            'save_failed': self._recover_save_failure,\n",
        "            'app_crash': self._recover_app_crash,\n",
        "            'dialog_stuck': self._recover_dialog_stuck\n",
        "        }\n",
        "    \n",
        "    def _recover_save_failure(self):\n",
        "        \"\"\"Recover from save operation failure\"\"\"\n",
        "        print(\"🔧 Recovering from save failure...\")\n",
        "        # Try alternative save method\n",
        "        self.workflow.automation.execute_shortcut('save_as')\n",
        "        time.sleep(2)\n",
        "        return True\n",
        "    \n",
        "    def _recover_app_crash(self):\n",
        "        \"\"\"Recover from application crash\"\"\"\n",
        "        print(\"🔧 Recovering from app crash...\")\n",
        "        # Relaunch application\n",
        "        return self.workflow.automation.launch_text_editor()\n",
        "    \n",
        "    def _recover_dialog_stuck(self):\n",
        "        \"\"\"Recover from stuck dialog\"\"\"\n",
        "        print(\"🔧 Recovering from stuck dialog...\")\n",
        "        # Press escape to close dialogs\n",
        "        pyautogui.press('escape')\n",
        "        time.sleep(1)\n",
        "        return True\n",
        "\n",
        "print(\"\\n=== Error Recovery Demo ===\")\n",
        "recovery = AutomationRecovery(workflow)\n",
        "print(\"🛠️ Recovery strategies available:\")\n",
        "for strategy in recovery.recovery_strategies:\n",
        "    print(f\"  - {strategy}\")\n",
        "\n",
        "print(\"\\n✅ Desktop automation concepts covered successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Advanced Python Features\n",
        "\n",
        "### Decorators, Generators, Context Managers, and Meta-programming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Python concepts for sophisticated automation\n",
        "\n",
        "# 1. DECORATORS - Essential for automation frameworks\n",
        "from functools import wraps, lru_cache\n",
        "import time\n",
        "from typing import Any, Callable, TypeVar, ParamSpec\n",
        "\n",
        "F = TypeVar('F', bound=Callable[..., Any])\n",
        "P = ParamSpec('P')\n",
        "T = TypeVar('T')\n",
        "\n",
        "# Performance monitoring decorator\n",
        "def performance_monitor(func: F) -> F:\n",
        "    \"\"\"Monitor function execution time and calls\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.perf_counter()\n",
        "        execution_time = end_time - start_time\n",
        "        \n",
        "        print(f\"⏱️ {func.__name__} executed in {execution_time:.4f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "# Retry decorator with exponential backoff\n",
        "def retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0, backoff_factor: float = 2.0):\n",
        "    \"\"\"Retry function with exponential backoff\"\"\"\n",
        "    def decorator(func: F) -> F:\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            last_exception = None\n",
        "            \n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except Exception as e:\n",
        "                    last_exception = e\n",
        "                    if attempt < max_retries - 1:\n",
        "                        delay = base_delay * (backoff_factor ** attempt)\n",
        "                        print(f\"🔄 Retry {attempt + 1}/{max_retries} after {delay:.1f}s: {e}\")\n",
        "                        time.sleep(delay)\n",
        "                    \n",
        "            print(f\"❌ All {max_retries} attempts failed\")\n",
        "            raise last_exception\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Caching decorator with TTL\n",
        "def timed_cache(ttl_seconds: int = 300):\n",
        "    \"\"\"Cache with time-to-live\"\"\"\n",
        "    def decorator(func: F) -> F:\n",
        "        cache = {}\n",
        "        cache_times = {}\n",
        "        \n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            # Create cache key\n",
        "            key = str(args) + str(sorted(kwargs.items()))\n",
        "            current_time = time.time()\n",
        "            \n",
        "            # Check if cached and not expired\n",
        "            if key in cache and (current_time - cache_times[key]) < ttl_seconds:\n",
        "                print(f\"🎯 Cache hit for {func.__name__}\")\n",
        "                return cache[key]\n",
        "            \n",
        "            # Execute function and cache result\n",
        "            result = func(*args, **kwargs)\n",
        "            cache[key] = result\n",
        "            cache_times[key] = current_time\n",
        "            print(f\"💾 Cached result for {func.__name__}\")\n",
        "            return result\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Validation decorator\n",
        "def validate_types(**type_checks):\n",
        "    \"\"\"Validate function argument types\"\"\"\n",
        "    def decorator(func: F) -> F:\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            # Get function signature\n",
        "            import inspect\n",
        "            sig = inspect.signature(func)\n",
        "            bound_args = sig.bind(*args, **kwargs)\n",
        "            bound_args.apply_defaults()\n",
        "            \n",
        "            # Check types\n",
        "            for param_name, expected_type in type_checks.items():\n",
        "                if param_name in bound_args.arguments:\n",
        "                    value = bound_args.arguments[param_name]\n",
        "                    if not isinstance(value, expected_type):\n",
        "                        raise TypeError(f\"Parameter '{param_name}' must be {expected_type.__name__}, got {type(value).__name__}\")\n",
        "            \n",
        "            return func(*args, **kwargs)\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Class decorator for automation\n",
        "def automation_component(name: str):\n",
        "    \"\"\"Mark class as automation component\"\"\"\n",
        "    def decorator(cls):\n",
        "        cls._automation_name = name\n",
        "        cls._is_automation_component = True\n",
        "        \n",
        "        # Add logging to all methods\n",
        "        for attr_name in dir(cls):\n",
        "            attr = getattr(cls, attr_name)\n",
        "            if callable(attr) and not attr_name.startswith('_'):\n",
        "                setattr(cls, attr_name, performance_monitor(attr))\n",
        "        \n",
        "        return cls\n",
        "    return decorator\n",
        "\n",
        "# Demo decorator usage\n",
        "@performance_monitor\n",
        "@retry_with_backoff(max_retries=2, base_delay=0.1)\n",
        "@timed_cache(ttl_seconds=10)\n",
        "def fetch_api_data(url: str) -> dict:\n",
        "    \"\"\"Simulate API call with decorators\"\"\"\n",
        "    print(f\"🌐 Fetching data from {url}\")\n",
        "    import random\n",
        "    if random.random() < 0.3:  # 30% chance of failure\n",
        "        raise ConnectionError(\"Simulated network error\")\n",
        "    return {\"data\": f\"Content from {url}\", \"timestamp\": time.time()}\n",
        "\n",
        "@validate_types(post_id=int, content=str)\n",
        "def process_blog_post(post_id: int, content: str) -> bool:\n",
        "    \"\"\"Process blog post with type validation\"\"\"\n",
        "    print(f\"📝 Processing post {post_id}: {content[:30]}...\")\n",
        "    return True\n",
        "\n",
        "# 2. GENERATORS - Memory efficient data processing\n",
        "def blog_post_generator(api_client, batch_size: int = 5):\n",
        "    \"\"\"Generate blog posts in batches\"\"\"\n",
        "    offset = 0\n",
        "    while True:\n",
        "        batch = api_client.get_posts(limit=batch_size, offset=offset)\n",
        "        if not batch:\n",
        "            break\n",
        "        for post in batch:\n",
        "            yield post\n",
        "        offset += batch_size\n",
        "\n",
        "def file_processor_generator(directory: Path, pattern: str = \"*.txt\"):\n",
        "    \"\"\"Generate file contents one at a time\"\"\"\n",
        "    for file_path in directory.glob(pattern):\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            yield file_path, content\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading {file_path}: {e}\")\n",
        "\n",
        "def chunked_processor(items, chunk_size: int = 10):\n",
        "    \"\"\"Process items in chunks\"\"\"\n",
        "    for i in range(0, len(items), chunk_size):\n",
        "        chunk = items[i:i + chunk_size]\n",
        "        yield chunk\n",
        "\n",
        "# Generator expressions and pipeline\n",
        "def process_posts_pipeline(posts):\n",
        "    \"\"\"Process posts using generator pipeline\"\"\"\n",
        "    # Filter valid posts\n",
        "    valid_posts = (post for post in posts if 'title' in post and 'body' in post)\n",
        "    \n",
        "    # Transform titles\n",
        "    formatted_posts = (\n",
        "        {**post, 'title': post['title'].title(), 'word_count': len(post['body'].split())}\n",
        "        for post in valid_posts\n",
        "    )\n",
        "    \n",
        "    # Filter by word count\n",
        "    substantial_posts = (post for post in formatted_posts if post['word_count'] > 10)\n",
        "    \n",
        "    return substantial_posts\n",
        "\n",
        "# 3. CONTEXT MANAGERS - Resource management\n",
        "from contextlib import contextmanager, ExitStack\n",
        "\n",
        "class AutomationSession:\n",
        "    \"\"\"Context manager for automation sessions\"\"\"\n",
        "    \n",
        "    def __init__(self, session_name: str):\n",
        "        self.session_name = session_name\n",
        "        self.start_time = None\n",
        "        self.resources = []\n",
        "    \n",
        "    def __enter__(self):\n",
        "        self.start_time = time.time()\n",
        "        print(f\"🚀 Starting automation session: {self.session_name}\")\n",
        "        return self\n",
        "    \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        duration = time.time() - self.start_time\n",
        "        if exc_type:\n",
        "            print(f\"❌ Session '{self.session_name}' failed after {duration:.2f}s: {exc_val}\")\n",
        "        else:\n",
        "            print(f\"✅ Session '{self.session_name}' completed in {duration:.2f}s\")\n",
        "        \n",
        "        # Cleanup resources\n",
        "        for resource in self.resources:\n",
        "            try:\n",
        "                resource.close()\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    def add_resource(self, resource):\n",
        "        \"\"\"Add resource for automatic cleanup\"\"\"\n",
        "        self.resources.append(resource)\n",
        "\n",
        "@contextmanager\n",
        "def temporary_directory():\n",
        "    \"\"\"Create and cleanup temporary directory\"\"\"\n",
        "    import tempfile\n",
        "    import shutil\n",
        "    \n",
        "    temp_dir = Path(tempfile.mkdtemp())\n",
        "    try:\n",
        "        print(f\"📁 Created temp directory: {temp_dir}\")\n",
        "        yield temp_dir\n",
        "    finally:\n",
        "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "        print(f\"🗑️ Cleaned up temp directory: {temp_dir}\")\n",
        "\n",
        "@contextmanager\n",
        "def error_logging(operation_name: str):\n",
        "    \"\"\"Context manager for error logging\"\"\"\n",
        "    try:\n",
        "        print(f\"🔄 Starting: {operation_name}\")\n",
        "        yield\n",
        "        print(f\"✅ Completed: {operation_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {operation_name} - {e}\")\n",
        "        raise\n",
        "\n",
        "# 4. METACLASSES AND DESCRIPTORS\n",
        "class AutoProperty:\n",
        "    \"\"\"Descriptor for automatic property validation\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, validator: Callable = None):\n",
        "        self.name = name\n",
        "        self.validator = validator\n",
        "        self.private_name = f'_{name}'\n",
        "    \n",
        "    def __get__(self, obj, objtype=None):\n",
        "        if obj is None:\n",
        "            return self\n",
        "        return getattr(obj, self.private_name, None)\n",
        "    \n",
        "    def __set__(self, obj, value):\n",
        "        if self.validator:\n",
        "            value = self.validator(value)\n",
        "        setattr(obj, self.private_name, value)\n",
        "    \n",
        "    def __delete__(self, obj):\n",
        "        delattr(obj, self.private_name)\n",
        "\n",
        "def positive_number(value):\n",
        "    \"\"\"Validator for positive numbers\"\"\"\n",
        "    if not isinstance(value, (int, float)) or value <= 0:\n",
        "        raise ValueError(\"Must be a positive number\")\n",
        "    return value\n",
        "\n",
        "def non_empty_string(value):\n",
        "    \"\"\"Validator for non-empty strings\"\"\"\n",
        "    if not isinstance(value, str) or not value.strip():\n",
        "        raise ValueError(\"Must be a non-empty string\")\n",
        "    return value.strip()\n",
        "\n",
        "class AutomationConfigMeta(type):\n",
        "    \"\"\"Metaclass for automation configuration classes\"\"\"\n",
        "    \n",
        "    def __new__(mcs, name, bases, namespace):\n",
        "        # Add automatic __init__ method\n",
        "        def __init__(self, **kwargs):\n",
        "            for key, value in kwargs.items():\n",
        "                if hasattr(self, key):\n",
        "                    setattr(self, key, value)\n",
        "        \n",
        "        namespace['__init__'] = __init__\n",
        "        \n",
        "        # Add validation method\n",
        "        def validate(self):\n",
        "            errors = []\n",
        "            for attr_name in dir(self):\n",
        "                attr = getattr(type(self), attr_name, None)\n",
        "                if isinstance(attr, AutoProperty):\n",
        "                    try:\n",
        "                        value = getattr(self, attr_name)\n",
        "                        if value is None:\n",
        "                            errors.append(f\"Required property '{attr_name}' is missing\")\n",
        "                    except Exception as e:\n",
        "                        errors.append(f\"Property '{attr_name}' validation failed: {e}\")\n",
        "            \n",
        "            if errors:\n",
        "                raise ValueError(\"Configuration validation failed: \" + \"; \".join(errors))\n",
        "            return True\n",
        "        \n",
        "        namespace['validate'] = validate\n",
        "        return super().__new__(mcs, name, bases, namespace)\n",
        "\n",
        "class BotConfiguration(metaclass=AutomationConfigMeta):\n",
        "    \"\"\"Automation bot configuration with automatic validation\"\"\"\n",
        "    \n",
        "    typing_speed = AutoProperty(\"typing_speed\", positive_number)\n",
        "    save_timeout = AutoProperty(\"save_timeout\", positive_number)\n",
        "    output_directory = AutoProperty(\"output_directory\", non_empty_string)\n",
        "    retry_attempts = AutoProperty(\"retry_attempts\", lambda x: max(1, int(x)))\n",
        "\n",
        "# 5. ADVANCED FUNCTION FEATURES\n",
        "def partial_application_demo():\n",
        "    \"\"\"Demonstrate partial application and currying\"\"\"\n",
        "    from functools import partial\n",
        "    \n",
        "    def save_file(directory: str, filename: str, content: str, encoding: str = 'utf-8'):\n",
        "        filepath = Path(directory) / filename\n",
        "        with open(filepath, 'w', encoding=encoding) as f:\n",
        "            f.write(content)\n",
        "        return filepath\n",
        "    \n",
        "    # Create specialized functions\n",
        "    save_to_output = partial(save_file, \"/tmp/output\")\n",
        "    save_utf8_to_output = partial(save_to_output, encoding='utf-8')\n",
        "    \n",
        "    return save_to_output, save_utf8_to_output\n",
        "\n",
        "# Demo usage\n",
        "print(\"=== Decorator Demo ===\")\n",
        "try:\n",
        "    result = fetch_api_data(\"https://api.example.com/posts\")\n",
        "    print(f\"📄 Result: {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Final error: {e}\")\n",
        "\n",
        "# Type validation demo\n",
        "try:\n",
        "    process_blog_post(123, \"Valid content\")\n",
        "    process_blog_post(\"invalid\", \"Content\")  # This will fail\n",
        "except TypeError as e:\n",
        "    print(f\"❌ Type validation error: {e}\")\n",
        "\n",
        "print(\"\\n=== Generator Demo ===\")\n",
        "# Simulate posts for generator demo\n",
        "sample_posts = [\n",
        "    {\"id\": 1, \"title\": \"first post\", \"body\": \"Short content\"},\n",
        "    {\"id\": 2, \"title\": \"second post\", \"body\": \"This is a much longer post with substantial content\"},\n",
        "    {\"id\": 3, \"title\": \"third post\", \"body\": \"Another post with good length and meaningful content\"}\n",
        "]\n",
        "\n",
        "processed = list(process_posts_pipeline(sample_posts))\n",
        "for post in processed:\n",
        "    print(f\"📝 {post['title']}: {post['word_count']} words\")\n",
        "\n",
        "# Chunked processing demo\n",
        "chunks = list(chunked_processor(range(25), chunk_size=7))\n",
        "print(f\"🔢 Processed {len(chunks)} chunks: {[len(chunk) for chunk in chunks]}\")\n",
        "\n",
        "print(\"\\n=== Context Manager Demo ===\")\n",
        "with AutomationSession(\"Demo Session\") as session:\n",
        "    with temporary_directory() as temp_dir:\n",
        "        with error_logging(\"File Creation\"):\n",
        "            test_file = temp_dir / \"test.txt\"\n",
        "            test_file.write_text(\"Demo content\")\n",
        "            print(f\"📄 Created: {test_file}\")\n",
        "\n",
        "print(\"\\n=== Metaclass Demo ===\")\n",
        "try:\n",
        "    config = BotConfiguration(\n",
        "        typing_speed=0.01,\n",
        "        save_timeout=5,\n",
        "        output_directory=\"/tmp/output\",\n",
        "        retry_attempts=3\n",
        "    )\n",
        "    config.validate()\n",
        "    print(\"✅ Configuration valid\")\n",
        "    print(f\"Typing speed: {config.typing_speed}\")\n",
        "except ValueError as e:\n",
        "    print(f\"❌ Configuration error: {e}\")\n",
        "\n",
        "# Invalid configuration demo\n",
        "try:\n",
        "    bad_config = BotConfiguration(typing_speed=-1)  # Invalid negative speed\n",
        "    bad_config.validate()\n",
        "except ValueError as e:\n",
        "    print(f\"❌ Expected validation error: {e}\")\n",
        "\n",
        "print(\"\\n=== Partial Application Demo ===\")\n",
        "save_to_output, save_utf8_to_output = partial_application_demo()\n",
        "print(\"🔧 Created specialized save functions\")\n",
        "\n",
        "# Advanced iteration patterns\n",
        "def advanced_iteration_patterns():\n",
        "    \"\"\"Demonstrate advanced iteration techniques\"\"\"\n",
        "    from itertools import chain, groupby, islice, cycle, combinations\n",
        "    \n",
        "    # Chain multiple iterables\n",
        "    list1 = [1, 2, 3]\n",
        "    list2 = [4, 5, 6]\n",
        "    list3 = [7, 8, 9]\n",
        "    chained = list(chain(list1, list2, list3))\n",
        "    print(f\"🔗 Chained: {chained}\")\n",
        "    \n",
        "    # Group by key\n",
        "    posts = [\n",
        "        {\"userId\": 1, \"title\": \"Post A\"},\n",
        "        {\"userId\": 1, \"title\": \"Post B\"},\n",
        "        {\"userId\": 2, \"title\": \"Post C\"},\n",
        "        {\"userId\": 2, \"title\": \"Post D\"},\n",
        "    ]\n",
        "    grouped = groupby(posts, key=lambda x: x[\"userId\"])\n",
        "    for user_id, user_posts in grouped:\n",
        "        post_titles = [p[\"title\"] for p in user_posts]\n",
        "        print(f\"👤 User {user_id}: {post_titles}\")\n",
        "    \n",
        "    # Take first N items\n",
        "    infinite_counter = cycle([1, 2, 3])\n",
        "    first_10 = list(islice(infinite_counter, 10))\n",
        "    print(f\"🔄 First 10 from cycle: {first_10}\")\n",
        "    \n",
        "    # Combinations\n",
        "    items = ['A', 'B', 'C', 'D']\n",
        "    pairs = list(combinations(items, 2))\n",
        "    print(f\"🔀 Combinations of 2: {pairs}\")\n",
        "\n",
        "print(\"\\n=== Advanced Iteration Demo ===\")\n",
        "advanced_iteration_patterns()\n",
        "\n",
        "# Memory efficient data processing\n",
        "def memory_efficient_processing():\n",
        "    \"\"\"Demonstrate memory-efficient techniques\"\"\"\n",
        "    \n",
        "    # Generator expression vs list comprehension\n",
        "    import sys\n",
        "    \n",
        "    # Memory usage comparison (conceptual)\n",
        "    numbers = range(1000000)\n",
        "    \n",
        "    # Generator expression - lazy evaluation\n",
        "    squares_gen = (x**2 for x in numbers if x % 2 == 0)\n",
        "    print(f\"🧠 Generator created (minimal memory)\")\n",
        "    \n",
        "    # Process first 5 items only\n",
        "    first_5_squares = list(islice(squares_gen, 5))\n",
        "    print(f\"🔢 First 5 even squares: {first_5_squares}\")\n",
        "    \n",
        "    # Demonstrate __slots__ for memory efficiency\n",
        "    class EfficientPost:\n",
        "        __slots__ = ['id', 'title', 'body', 'user_id']\n",
        "        \n",
        "        def __init__(self, id, title, body, user_id):\n",
        "            self.id = id\n",
        "            self.title = title\n",
        "            self.body = body\n",
        "            self.user_id = user_id\n",
        "    \n",
        "    efficient_post = EfficientPost(1, \"Test\", \"Content\", 1)\n",
        "    print(f\"💾 Efficient post created with __slots__\")\n",
        "\n",
        "print(\"\\n=== Memory Efficiency Demo ===\")\n",
        "memory_efficient_processing()\n",
        "\n",
        "print(\"\\n✅ Advanced Python features demonstration complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
